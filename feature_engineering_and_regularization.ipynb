{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNy7G2wlrFY+jeSn2Hdse5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dasd412/my-first-ai/blob/main/feature_engineering_and_regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7gTLEcdF5yR"
      },
      "outputs": [],
      "source": [
        "# 특성 공학 : 기존의 특성을 사용해 새로운 특성을 뽑아내는 작업\n",
        "# (ex) 농어 길이 x 농어 높이를 새로운 특성으로 만들기\n",
        "# 선형 회귀는 특성이 많을수록 엄청난 효과를 낸다. (매우 복잡한 모델을 표현할 수 있음)\n",
        "# 여러 개의 특성을 사용한 선형 회귀를 '다중 회귀'라고 한다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read_csv()에 url을 넣은 후, 데이터 프레임을 만든다.\n",
        "df=pd.read_csv('https://bit.ly/perch_csv_data')\n",
        "# 데이터 프레임을 넘파이 배열로 바꾼다.\n",
        "perch_full=df.to_numpy()\n",
        "\n",
        "print(perch_full)"
      ],
      "metadata": {
        "id": "HCvjdt7hJyLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 타깃 데이터\n",
        "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
        "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
        "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
        "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
        "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
        "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
        "       1000.0])\n"
      ],
      "metadata": {
        "id": "xaSN43B6KRXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_input, test_input,train_target,test_target=train_test_split(perch_full,perch_weight,random_state=42)"
      ],
      "metadata": {
        "id": "nQhCGlRJKdj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런의 변환기 : 특성을 만들거나 전처리하기 위한 클래스들\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# 예제로, 2개의 특성 2와 3으로 이루어진 샘플 하나 적용해보기\n",
        "poly=PolynomialFeatures()\n",
        "poly.fit([[2,3]]) # transform() 전에 fit()을 해야 한다!!\n",
        "print(poly.transform([[2,3]]))"
      ],
      "metadata": {
        "id": "_cBAdGGQKpsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit()은 새롭게 만들 특성 조합을 찾고, transform()은 실제로 데이터를 변환한다.\n",
        "# 그리고 변환기는 타깃 데이터 없이, 입력 데이터를 변환해준다.\n",
        "# PolynomialFeatures 는 기본적으로 각 특성을 제곱한 항을 추가하고 특성끼리 서로 곱한 항을 추가한다.\n",
        "\n",
        "poly=PolynomialFeatures(include_bias=False) # include_bias = False 면 특성 1이 나오지 않게 된다. (절편 값 무시)\n",
        "poly.fit([[2,3]])\n",
        "print(poly.transform([[2,3]]))\n"
      ],
      "metadata": {
        "id": "_ZZ9BgyZLMyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly=PolynomialFeatures(include_bias=False)\n",
        "\n",
        "poly.fit(train_input)\n",
        "train_poly=poly.transform(train_input)\n",
        "print(train_poly.shape) # (데이터의 개수, 특성 개수)"
      ],
      "metadata": {
        "id": "ZJaoez5yMDPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9개의 특성이 각각 어떤 입력의 조합으로 만들어졌는지 알려주는 메서드\n",
        "poly.get_feature_names_out()"
      ],
      "metadata": {
        "id": "n2f1aNHaMYmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 세트도 변환\n",
        "test_poly=poly.transform(test_input)"
      ],
      "metadata": {
        "id": "4BXEd13SMrf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다중 회귀는 여러 개의 특성을 사용하여 선형 회귀를 수행하는 것이기 때문에, 선형 회귀 모델을 훈련하는 것과 같은 방식으로 훈련한다.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr=LinearRegression()\n",
        "lr.fit(train_poly,train_target)\n",
        "print(lr.score(train_poly,train_target)) # 특성이 늘어나면, 선형 회귀 예측 점수가 좋아짐을 확인함."
      ],
      "metadata": {
        "id": "p16QA_2gMxii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.score(test_poly,test_target))"
      ],
      "metadata": {
        "id": "2-9jIlWnOzv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PolynomialFeatures()의 degree 매개 변수를 활용하면, 필요한 고차항의 최대 차수를 지정할 수  있다.\n",
        "poly=PolynomialFeatures(degree=5,include_bias=False)# 5제곱 까지 특성을 만들어서 특성을 더 추가해본다.\n",
        "\n",
        "poly.fit(train_input)\n",
        "train_poly=poly.transform(train_input)\n",
        "test_poly=poly.transform(test_input)\n",
        "\n",
        "print(train_poly.shape) # 만들어진 특성이 55개나 된다."
      ],
      "metadata": {
        "id": "BSC66UGcO5Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(train_poly,train_target)\n",
        "print(lr.score(train_poly,train_target)) # 훈련 점수는 더 좋아졌다."
      ],
      "metadata": {
        "id": "3sC5Y2_fPb02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lr.score(test_poly,test_target)) # 값이 음수가 나온다!!\n",
        "# 원인 : 특성의 개수를 크게 늘리면 선형 모델은 강력해진다. 그래서 훈련 세트에 대해선 거의 완벽하게 학습할 수 있다.\n",
        "# 하지만, 이런 모델은 훈련 세트에 너무 과대 적합되므로 테스트 세트에서는 점수가 매우 낮아진다."
      ],
      "metadata": {
        "id": "ys0mMewmPtGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 규제(regularization)는 머신 러닝 모델이 훈련 세트를 너무 과도하게 학습하지 못하게 훼방하는 장치이다.\n",
        "# 선형 회귀 모델에서는 특성에 곱해지는 계수(기울기)의 크기를 작게 만든다.\n",
        "\n",
        "# 그런데 특성의 스케일이 정규화되지 않으면, 여기에 곱해지는 계수 값도 차이가 나게 된다. 그래서 선형 회귀 모델에 규제를 적용할 때 계수 값의 크기가\n",
        "# 서로 많이 다르면 공정하게 제어되지 않는다. 즉, 규제를 적용하기 전에 먼저 정규화를 진행한다.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "ss=StandardScaler()\n",
        "ss.fit(train_poly)#훈련 세트로 학습\n",
        "train_scaled=ss.transform(train_poly)\n",
        "test_scaled=ss.transform(test_poly) # 반드시 훈련 세트로 학습한 변환기를 사용해서 테스트 세트까지 변환되어야만 한다!!"
      ],
      "metadata": {
        "id": "gxRiRatVQSxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 회귀 모델에 규제를 추가한 모델을 릿지와 라쏘라고 한다.\n",
        "# 릿지 : 계수를 제곱한 값을 기준으로 규제를 적용\n",
        "# 라쏘 : 계수의 절댓값을 기준으로 규제를 적용 (크기를 아예 0으로 만들 수 도 있음)"
      ],
      "metadata": {
        "id": "PxCbzYDeRhrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge=Ridge()\n",
        "ridge.fit(train_scaled,train_target)\n",
        "print(ridge.score(train_scaled,train_target))"
      ],
      "metadata": {
        "id": "m5gubO4hWPKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ridge.score(test_scaled,test_target)) # 규제를 적용한 결과, 훈련 세트에 과대 적합했던 문제를 해결하였음."
      ],
      "metadata": {
        "id": "uk0rbLEjWgiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 릿지와 라쏘 모델을 사용할 때, 규제의 양을 임의로 조정할 수 있다.\n",
        "# 모델 객체를 만들 때 alpha 매개변수로 규제의 강도를 조절한다. alpha 값이 커지면 규제 강도가 세지므로 계수값을 더 줄이고 조금 더 과소적합되도록 유도한다.\n",
        "# alpha 값이 작으면 계수를 줄이는 역할이 줄어들고 선형회귀 모델과 유사해지므로 과대적합될 가능성이 커진다.\n",
        "\n",
        "# alpha 값과 같이, 모델이 학습하는 값이 아니라 사전에 사람이 직접 지정해야 하는 매개변수를 '하이퍼 파라미터'라고 한다."
      ],
      "metadata": {
        "id": "vtWPWzeZWwrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 적절한 alpha 값을 찾는 방법 중 하나는 alpha 값에 대한 R^2 그래프를 그려보는 것이다.\n",
        "# 훈련 세트와 테스트 세트의 점수가 가장 가까운 지점이 최적의 alpha 값이 된다.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_score=[]\n",
        "test_score=[]\n"
      ],
      "metadata": {
        "id": "DKngwb51XJpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha_list=[0.001, 0.01, 0.1,1,10,100]\n",
        "\n",
        "for alpha in alpha_list:\n",
        "    # 릿지 모델을 만든다.\n",
        "    ridge=Ridge(alpha=alpha)\n",
        "    #릿지 모델을 훈련시킨다.\n",
        "    ridge.fit(train_scaled,train_target)\n",
        "\n",
        "    # 훈련 세트와 테스트 세트 점수를 저장한다.\n",
        "    train_score.append(ridge.score(train_scaled,train_target))\n",
        "    test_score.append(ridge.score(test_scaled,test_target))"
      ],
      "metadata": {
        "id": "-QM9ljniXgA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.log10(alpha_list),train_score) # alpha 값이 10배씩 차이나므로 로그를 씌워서 간격을 비슷하게 한다.\n",
        "plt.plot(np.log10(alpha_list),test_score)\n",
        "\n",
        "# 위 그래프가 훈련 세트, 아래 그래프가 테스트 테스트를 나타낸다.\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('R^2')\n",
        "plt.show()\n",
        "\n",
        "# alpha 값 10^-1=0.1이 훈련 세트와 테스트 세트의 점수가 가장 가까운 지점이므로 최적의 alpha 값이 된다.\n",
        "# 그 왼쪽은 과대적합을, 그 오른쪽은 과소적합 경향을 보이고 있다."
      ],
      "metadata": {
        "id": "v2QpX7V0X6-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#최적의 alpha 값을 기준으로 규제를 적용해서 훈련\n",
        "ridge=Ridge(alpha=0.1)\n",
        "ridge.fit(train_scaled,train_target)\n",
        "\n",
        "print(ridge.score(train_scaled,train_target))\n",
        "print(ridge.score(test_scaled,test_target))\n"
      ],
      "metadata": {
        "id": "swHEI_JMYTFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라쏘 모델 훈련해보기\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso=Lasso()\n",
        "lasso.fit(train_scaled,train_target)\n",
        "print(lasso.score(train_scaled,train_target))"
      ],
      "metadata": {
        "id": "c0tePXc0Y7xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lasso.score(test_scaled,test_target))"
      ],
      "metadata": {
        "id": "W4_M8OuLZl_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_score=[]\n",
        "test_score=[]\n",
        "\n",
        "alpha_list=[0.001, 0.01, 0.1,1,10,100]\n",
        "\n",
        "for alpha in alpha_list:\n",
        "    # 라쏘 모델 만들기\n",
        "    lasso=Lasso(alpha=alpha, max_iter=10000)\n",
        "\n",
        "    lasso.fit(train_scaled,train_target)\n",
        "\n",
        "    train_score.append(lasso.score(train_scaled,train_target))\n",
        "    test_score.append(lasso.score(test_scaled,test_target))"
      ],
      "metadata": {
        "id": "SU7eeSUzZyQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.log10(alpha_list),train_score)\n",
        "plt.plot(np.log10(alpha_list),test_score)\n",
        "\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('R^2')\n",
        "plt.show()\n",
        "# 위쪽이 훈련 세트 그래프, 아래쪽이 테스트 세트 그래프. 이 모델에서 가장 적합한 alpha 값은 1, 10^1=10이다."
      ],
      "metadata": {
        "id": "6NdlmJc6aPe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso=Lasso(alpha=10)\n",
        "\n",
        "lasso.fit(train_scaled,train_target)\n",
        "\n",
        "print(lasso.score(train_scaled,train_target))\n",
        "print(lasso.score(test_scaled,test_target))"
      ],
      "metadata": {
        "id": "X33XT7o-ampO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라쏘 모델은 계수값을 아예 0으로 만들 수도 있다. 다음은 0이 된 값의 개수를 보여준다.\n",
        "print(np.sum(lasso.coef_==0))"
      ],
      "metadata": {
        "id": "MTNbl3fya2RP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}