{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNB5Mffv0/7M5PhWqd3PRQ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dasd412/my-first-ai/blob/main/knn_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAJuow7hFP-L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 농어의 길이를 가지고 농어의 무게를 예측해보자! 회귀(regression)는 임의의 값을 예측하는 문제이다. 따라서 타깃값도 임의의 수치가 된다.\n",
        "\n",
        "perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,\n",
        "       21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,\n",
        "       23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,\n",
        "       27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,\n",
        "       39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,\n",
        "       44.0])\n",
        "perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,\n",
        "       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,\n",
        "       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,\n",
        "       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,\n",
        "       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,\n",
        "       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,\n",
        "       1000.0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성인 농어의 길이를 x축에, 타깃인 농어의 무게를 y축에 놓고 그려본다.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(perch_length, perch_weight)\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('weight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qAWj6kA1Fjw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 농어 데이터를 훈련 세트와 테스트 세트로 나눔. (테스트 데이터는 전체 데이터의 20~30 퍼센트를 차지한다.)\n",
        "# 사이킷런에 사용할 훈련 세트는 2차원 배열이여야 한다. \n",
        "train_input,test_input,train_target,test_target=train_test_split(perch_length,perch_weight,random_state=42)"
      ],
      "metadata": {
        "id": "vyY8HPROF5e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_array=np.array([1,2,3,4])\n",
        "print(test_array.shape)"
      ],
      "metadata": {
        "id": "bWX-VUg0GOp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (4,) 넘파이 배열을 (2,2) 배열로 바꿔보자.\n",
        "test_array=test_array.reshape(2,2) # reshape() 메서드는 크기가 바뀐 새로운 배열을 반환할 때, 지정한 크기가 원본 배열에 있는 원소의 개수가 다르면 에러 발생! (바꾸기 전후의 배열 원소 개수는 동일해야 함.)\n",
        "print(test_array.shape)"
      ],
      "metadata": {
        "id": "3g8e61Z_G04a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 크기에 -1을 지정하면 reshape()는 나머지 원소로 모두 채운다.\n",
        "# 아래는 첫 번째 크기를 나머지 원소로 채우고, 두 번째 크기를 1로 하는 코드다.\n",
        "train_input=train_input.reshape(-1,1)\n",
        "test_input=test_input.reshape(-1,1)\n",
        "print(train_input,test_input)\n",
        "print(train_input.shape,test_input.shape)"
      ],
      "metadata": {
        "id": "ywePiyLGHUgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#최근접 이웃 회귀 알고리즘 구현\n",
        "#예측하려는 샘플에 가장 가까운 샘플 k개를 선택함\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "knr=KNeighborsRegressor()\n",
        "\n",
        "knr.fit(train_input,train_target)\n"
      ],
      "metadata": {
        "id": "VQQMWs1jIM3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#분류의 경우, 테스트 세트에 있는 샘플을 정확하게 분류한 개수의 비율이 점수로 나왔다. (정확도라고 했었음)\n",
        "#반면 이번 예제처럼 회귀의 경우, 정확한 숫자를 맞히는 것은 불가능함. 예측하는 값이나 타깃 모두 임의의 수치이기 때문!\n",
        "print(knr.score(test_input,test_target))"
      ],
      "metadata": {
        "id": "QjuP_THeIzw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 회귀의 경우, 다른 값으로 평가하는데 이 점수를 결정 계수 (R^2)라고 한다.\n",
        "# R^2 = (타깃 - 예측)^2의 합 // (타깃 - 평균)^2의 합\n",
        "# 타깃의 평균정도를 예측하는 수준이라면, 분자와 분모가 비슷해져 결정 계수는 0에 가까워진다.\n",
        "# 반면 예측이 타깃에 아주 가까워지면, 분자가 0에 가까워지므로 결정 계수는 1에 가까운 값이 된다.\n",
        "# 1에 가까울 수록 좋은 모델, 0에 가까울수록 성능이 나쁜 모델이다."
      ],
      "metadata": {
        "id": "nj9gRUuEJPv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 테스트 세트에 대한 예측을 만듬\n",
        "test_prediction=knr.predict(test_input)\n",
        "\n",
        "# 테스트 세트에 대한 평균 절댓값 오차를 계산함. 아래 메서드는 타깃과 예측의 절댓값 오차를 평균하여 반환한다. (타깃과 예측한 값의 차이를 구해보면 어느 정도 예측이 벗어났는지 가늠하기 좋다.)\n",
        "mae=mean_absolute_error(test_target,test_prediction)\n",
        "\n",
        "print(mae)"
      ],
      "metadata": {
        "id": "D17tnYhJJ_lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 지금까지는 훈련  세트를 사용해 모델을 훈련하고 테스트 세트로 모델을 평가했다.\n",
        "# 이번에는 훈련 세트를 사용해 평가해보자. \n",
        "# 결과를 보면, knr.score(test_input,test_target) 보다 낮은 값이 나온다. 즉, 테스트 세트로 평가한 것보다 훈련 세트로 평가한 것이 더 낮게 나왔다. 과소 적합된 사례이다.\n",
        "print(knr.score(train_input,train_target))"
      ],
      "metadata": {
        "id": "fSj_QSeyKyvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 과대적합 (overfitting) : 훈련 세트 점수는 굉장히 좋았는데, 테스트 세트에서는 점수가 굉장히 나쁜 경우. \n",
        "# 과대적합이 발생하면, 훈련세트에만 잘 맞는 모델이기 때문에 실전에 투입해도 새로운 샘플에 대한 예측을 잘 못하게 된다. (모델이 훈련 세트에 집착해서 데이터의 거시적인 패턴을 감지하지 못하는 경우이다.)\n",
        "\n",
        "# 과소 적합 (underfitting): 훈련 세트보다 테스트 세트의 점수가 높거나, 두 점수가 모두 낮은 경우\n",
        "# 모델이 너무 단순해서 훈련 세트에 적절히 훈련되지 않은 경우다. 아니면 데이터가 너무 적거나...\n"
      ],
      "metadata": {
        "id": "hCeoYoXOM9u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 예시에서는 과소적합이 일어났으므로 모델을 좀더 복잡하게 만들면 된다.\n",
        "# knn 회귀 모델을 복잡하게 만드는 것은 이웃의 개수 k를 줄이는 것이다.(이웃의 개수를 줄이면 훈련 세트에 있는 국지적인 패턴에 민감해짐)\n",
        "\n",
        "knr.n_neighbors=3\n",
        "\n",
        "knr.fit(train_input,train_target)\n",
        "print(knr.score(train_input,train_target))"
      ],
      "metadata": {
        "id": "YJmcjNLqL832"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(knr.score(test_input,test_target))\n",
        "# 테스트 세트의 점수가 훈련 세트의 점수보다 낮아졌으므로 과소적합 문제 해결."
      ],
      "metadata": {
        "id": "EoDP0O8ROMXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 농어 길이를 5에서 45까지 바꿔가며 예측을 만들어보자. 그리고 그래프를 나타내보자.\n",
        "knr=KNeighborsRegressor()\n",
        "\n",
        "# 5에서 45까지 x좌표 만들기\n",
        "x=np.arange(5,45).reshape(-1,1)\n",
        "\n",
        "for n in [1,5,10]:\n",
        "    knr.n_neighbors=n\n",
        "    knr.fit(train_input,train_target)\n",
        "\n",
        "    # 지정된 범위 x에 대한 예측을 구함\n",
        "    prediction=knr.predict(x)\n",
        "\n",
        "    plt.scatter(train_input,train_target)\n",
        "    plt.plot(x,prediction)\n",
        "    plt.title('n_neighbors={}'.format(n))\n",
        "\n",
        "    plt.xlabel('length')\n",
        "    plt.ylabel('weight')\n",
        "\n",
        "    plt.show()\n",
        "# 이웃의 개수 n이 커짐에 따라 모델이 단순해짐을 알 수 있다!"
      ],
      "metadata": {
        "id": "4dEjundgQptY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}